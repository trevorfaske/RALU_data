{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Does everything to run entropy and creates slurm files to submit\n",
    "\n",
    "Goal is 4 chains k=2-11. (10 populations) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/bin/sh: line 0: source: activate: file not found\r\n"
     ]
    }
   ],
   "source": [
    "!source activate py36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "#sys.path.append('/home/faske/g/anaconda3/envs/py34/lib/python3.4/site-packages')\n",
    "sys.path.append('/data/gpfs/assoc/parchmanlab/tfaske/anaconda3/envs/py36/lib/python3.6/site-packages')\n",
    "sys.path.append(\"/data/gpfs/assoc/parchmanlab/tfaske/ipynb/include_utils\")\n",
    "\n",
    "import ipyparallel as ipp\n",
    "import os, time\n",
    "import include_utils as u\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import random\n",
    "import numbers\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as mcolors\n",
    "#import vcf\n",
    "from sklearn import preprocessing\n",
    "from subprocess import Popen, PIPE, call, check_output\n",
    "import seaborn as sns\n",
    "from IPython.display import FileLink\n",
    "import urllib.request as urllib2\n",
    "import dill\n",
    "import traceback\n",
    "from pandas import Series, DataFrame\n",
    "import gzip\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore',category=pd.io.pytables.PerformanceWarning)\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "from Bio import SeqIO\n",
    "#import pysam\n",
    "from collections import OrderedDict, namedtuple, Counter\n",
    "import operator\n",
    "import multiprocessing as mp\n",
    "import shutil\n",
    "import tempfile\n",
    "#from ipyparallel import Client\n",
    "import scandir\n",
    "import glob\n",
    "from Bio.SeqIO.QualityIO import FastqGeneralIterator\n",
    "import pickle\n",
    "import re\n",
    "from itertools import chain\n",
    "#import Levenshtein as lv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '/data/gpfs/home/tfaske/d/milkweed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/gpfs/assoc/denovo/tfaske/milkweed\n"
     ]
    }
   ],
   "source": [
    "cd $root"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create mgpl & pntest files with associated dir "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "ent_dir =os.path.join(root,'entropy')\n",
    "assert ent_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/gpfs/assoc/denovo/tfaske/milkweed/entropy\n"
     ]
    }
   ],
   "source": [
    "cd $ent_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gunzip 'good_snps.recode.vcf.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'good_snps.recode.vcf'"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vcf = 'good_snps.recode.vcf'\n",
    "vcf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "perl_mpgl = '/data/gpfs/home/tfaske/g/src/perl_scripts/vcf2mpgl_milkweed.pl'\n",
    "perl_mean = '/data/gpfs/home/tfaske/g/src/perl_scripts/gl2genest_milkweed.pl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of loci: 18083; number of individuals 143\r\n"
     ]
    }
   ],
   "source": [
    "!perl $perl_mpgl $vcf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpgl = 'good_snps.recode.mpgl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "!perl $perl_mean $mpgl mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create ldak files in R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The rpy2.ipython extension is already loaded. To reload it, use:\n",
      "  %reload_ext rpy2.ipython\n"
     ]
    }
   ],
   "source": [
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Loading required package: LEA\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "require(readr)\n",
    "require(MASS)\n",
    "require(LEA)\n",
    "require(ggplot2)\n",
    "\n",
    "source('/data/gpfs/home/tfaske/g/src/R/Imports.R')\n",
    "\n",
    "setwd('/data/gpfs/home/tfaske/d/milkweed/entropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Pop  ID       All\n",
      "1  BM 607 FA_BM_607\n",
      "2  BM 608 FA_BM_608\n",
      "3  BM 609 FA_BM_609\n",
      "4  BM 610 FA_BM_610\n",
      "5  BM 611 FA_BM_611\n",
      "6  BM 612 FA_BM_612\n",
      "[1] 10\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "#create Pop_ID file \n",
    "\n",
    "indv<-read.table(\"../filtering/good_snps.recode.vcf.012.indv\",sep=\"\\t\")\n",
    "\n",
    "Pop <- rep(NA,times=nrow(indv))\n",
    "ID <- rep(NA,times=nrow(indv))\n",
    "All <- rep(NA,times=nrow(indv))\n",
    "for (i in 1:nrow(indv)){\n",
    "    fq <- unlist(strsplit(as.character(indv$V1[i]),\"/\"))[7]\n",
    "    name <- unlist(strsplit(as.character(fq),\".fastq.gz_sorted.bam\"))[1]\n",
    "    Pop[i] <- unlist(strsplit(as.character(name),\"_\"))[2]\n",
    "    ID[i] <- unlist(strsplit(as.character(name),\"_\"))[3]\n",
    "    All[i] <- as.character(name)\n",
    "}\n",
    "Pop_ID <- data.frame(Pop=Pop,ID=ID,All=All)\n",
    "print(head(Pop_ID))\n",
    "print(length(unique(Pop_ID$Pop)))\n",
    "write.csv(Pop_ID,'Pop_ID.csv',row.names=F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 18083   143\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "g <- read.table(\"pntest_mean_good_snps.recode.txt\", header=F)\n",
    "dim(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    PC1     PC2     PC3     PC4     PC5 \n",
      "0.08829 0.06179 0.04976 0.04451 0.03475 \n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "Pop_ID <- read.csv(\"Pop_ID.csv\")\n",
    "pca_df <- PCA_entropy(t(g))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "#######################################################################################\n",
    "                                    #### LDA ####\n",
    "#######################################################################################\n",
    "\n",
    "k2<-kmeans(pca_df[,1:5],2,iter.max=10,nstart=10,algorithm=\"Hartigan-Wong\")\n",
    "k3<-kmeans(pca_df[,1:5],3,iter.max=10,nstart=10,algorithm=\"Hartigan-Wong\")\n",
    "k4<-kmeans(pca_df[,1:5],4,iter.max=10,nstart=10,algorithm=\"Hartigan-Wong\")\n",
    "k5<-kmeans(pca_df[,1:5],5,iter.max=10,nstart=10,algorithm=\"Hartigan-Wong\")\n",
    "k6<-kmeans(pca_df[,1:5],6,iter.max=10,nstart=10,algorithm=\"Hartigan-Wong\")\n",
    "k7<-kmeans(pca_df[,1:5],7,iter.max=10,nstart=10,algorithm=\"Hartigan-Wong\")\n",
    "k8<-kmeans(pca_df[,1:5],8,iter.max=10,nstart=10,algorithm=\"Hartigan-Wong\")\n",
    "k9<-kmeans(pca_df[,1:5],9,iter.max=10,nstart=10,algorithm=\"Hartigan-Wong\")\n",
    "k10<-kmeans(pca_df[,1:5],10,iter.max=10,nstart=10,algorithm=\"Hartigan-Wong\")\n",
    "k11<-kmeans(pca_df[,1:5],11,iter.max=10,nstart=10,algorithm=\"Hartigan-Wong\")\n",
    "\n",
    "ldak2<-lda(x=pca_df[,1:5],grouping=k2$cluster,CV=TRUE)\n",
    "ldak3<-lda(x=pca_df[,1:5],grouping=k3$cluster,CV=TRUE)\n",
    "ldak4<-lda(x=pca_df[,1:5],grouping=k4$cluster,CV=TRUE)\n",
    "ldak5<-lda(x=pca_df[,1:5],grouping=k5$cluster,CV=TRUE)\n",
    "ldak6<-lda(x=pca_df[,1:5],grouping=k6$cluster,CV=TRUE)\n",
    "ldak7<-lda(x=pca_df[,1:5],grouping=k7$cluster,CV=TRUE)\n",
    "ldak8<-lda(x=pca_df[,1:5],grouping=k8$cluster,CV=TRUE)\n",
    "ldak9<-lda(x=pca_df[,1:5],grouping=k9$cluster,CV=TRUE)\n",
    "ldak10<-lda(x=pca_df[,1:5],grouping=k10$cluster,CV=TRUE)\n",
    "ldak11<-lda(x=pca_df[,1:5],grouping=k11$cluster,CV=TRUE)\n",
    "\n",
    "write.table(round(ldak2$posterior,5),file=\"ldak2.txt\",quote=F,row.names=F,col.names=F)\n",
    "write.table(round(ldak3$posterior,5),file=\"ldak3.txt\",quote=F,row.names=F,col.names=F)\n",
    "write.table(round(ldak4$posterior,5),file=\"ldak4.txt\",quote=F,row.names=F,col.names=F)\n",
    "write.table(round(ldak5$posterior,5),file=\"ldak5.txt\",quote=F,row.names=F,col.names=F)\n",
    "write.table(round(ldak6$posterior,5),file=\"ldak6.txt\",quote=F,row.names=F,col.names=F)                                      \n",
    "write.table(round(ldak7$posterior,5),file=\"ldak7.txt\",quote=F,row.names=F,col.names=F)\n",
    "write.table(round(ldak8$posterior,5),file=\"ldak8.txt\",quote=F,row.names=F,col.names=F)\n",
    "write.table(round(ldak9$posterior,5),file=\"ldak9.txt\",quote=F,row.names=F,col.names=F)\n",
    "write.table(round(ldak10$posterior,5),file=\"ldak10.txt\",quote=F,row.names=F,col.names=F)\n",
    "write.table(round(ldak11$posterior,5),file=\"ldak11.txt\",quote=F,row.names=F,col.names=F)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "######### create entropy header ####\n",
    "\n",
    "Pop_ID_list <- paste(Pop_ID$Pop,Pop_ID$ID,sep='_')\n",
    "\n",
    "Header <- data.frame(dims = NA,Pop_ID_list)\n",
    "\n",
    "dim(g)\n",
    "\n",
    "df <- t(Header)\n",
    "dims <- paste(dim(g)[2],dim(g)[1],sep = \" \")\n",
    "\n",
    "df[1,1] <- dims\n",
    "\n",
    "write.table(df,'entropy_header.txt',sep = \" \",na =\"\",\n",
    "            quote = FALSE,row.names = FALSE,col.names = FALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143 18083                                                                                                                                              \r\n",
      "BM_607 BM_608 BM_609 BM_610 BM_611 BM_612 BM_613 BM_614 BM_615 BM_616 BM_635 BM_636 BM_637 BM_638 BM_639 BM_640 BM_641 BM_642 BM_643 BM_644 BM_645 BM_646 BM_647 CP_556 CP_557 CP_558 CP_559 CP_560 CP_561 CP_562 CP_563 CP_564 CP_565 CP_566 CP_567 DG_745 DG_746 DG_747 DG_748 DG_749 DG_750 DG_751 DG_752 DG_753 DG_754 DG_755 DG_756 DP_801 DP_802 DP_803 DP_804 DP_805 DP_806 DP_807 DP_808 DP_810 LA_661 LA_662 LA_663 LA_664 LA_665 LA_666 LA_667 LA_668 LA_669 LA_670 LS_757 LS_758 LS_759 LS_760 LS_761 LS_762 LS_763 LS_764 LS_765 LS_766 LS_767 LS_768 LS_769 LS_770 LS_771 LS_772 LS_773 LV_774 LV_775 LV_776 LV_777 LV_778 LV_779 LV_780 LV_781 LV_782 LV_783 LV_784 LV_785 LV_786 LV_787 LV_788 NI_583 NI_585 NI_586 NI_592 NI_593 NI_594 SN_17 SN_19 SN_23 SN_24 SN_29 SN_32 SN_33 SN_34 SN_35 SN_36 SN_37 SN_38 SN_39 SN_40 SN_41 SN_42 SN_43 SN_44 SN_46 SN_47 SN_48 SN_49 SN_50 WC_722 WC_723 WC_724 WC_725 WC_727 WC_729 WC_730 WC_731 WC_732 WC_733 WC_735 WC_736 WC_737 WC_738 WC_740 WC_741\r\n"
     ]
    }
   ],
   "source": [
    "!head entropy_header.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat entropy_header.txt good_snps.recode.mpgl > entropy.mpgl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/gpfs/assoc/denovo/tfaske/milkweed/entropy\n"
     ]
    }
   ],
   "source": [
    "cd $ent_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir shdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "### select slurm options\n",
    "account = 'cpu-s5-denovo-0'\n",
    "partition = 'cpu-core-0'\n",
    "time = '4-00:00:00' #time limit 4\n",
    "cpus = 4 #to prevent hammering one node\n",
    "mem_cpu = 8000\n",
    "email = 'tfaske@nevada.unr.edu'\n",
    "\n",
    "#entropy settings\n",
    "l = 60000\n",
    "b = 10000\n",
    "num_k = [2,3,4,5,6,7,8,9,10,11]\n",
    "chains = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_entropy_sh(account,partition,time,cpus,mem_cpu,email,l,b,num_k,chains):\n",
    "    for k in num_k:\n",
    "        for c in range(1,chains+1):\n",
    "            jobname = 'k%d_c%d' % (k,c)\n",
    "            seed = random.randint(1000,9999) #default is clock so messes up if submitted same time \n",
    "            with open(\"shdir/run_entropy_%s.sh\" % (jobname), \"w\") as o:\n",
    "                o.write(\"\"\"#!/usr/bin/env bash\n",
    "#SBATCH --account=%s\n",
    "#SBATCH --partition=%s\n",
    "#SBATCH --time=%s\n",
    "#SBATCH --ntasks 1\n",
    "#SBATCH --cpus-per-task %d\n",
    "#SBATCH --mem-per-cpu=%d\n",
    "#SBATCH --job-name ent_%s\n",
    "#SBATCH --output output_%s.txt\n",
    "#SBATCH --mail-type=END\n",
    "#SBATCH --mail-user=%s\\n\\n\"\"\" % (account,partition,time,cpus,mem_cpu,jobname,jobname,email))\n",
    "        \n",
    "                o.write(\"entropy -i ../entropy.mpgl -o ../entropy_%s.hdf5 -r %d -n 2 -l %d -b %d -t 10 -s 50 -e .01 -k %d -q ../ldak%d.txt -m 1 -w 0\"\n",
    "                        % (jobname,seed,l,b,k,k))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_entropy_sh(account,partition,time,cpus,mem_cpu,email,l,b,num_k,chains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/data/gpfs/home/tfaske/d/milkweed/entropy/shdir/run_entropy_k10_c1.sh',\n",
       " '/data/gpfs/home/tfaske/d/milkweed/entropy/shdir/run_entropy_k10_c2.sh',\n",
       " '/data/gpfs/home/tfaske/d/milkweed/entropy/shdir/run_entropy_k10_c3.sh',\n",
       " '/data/gpfs/home/tfaske/d/milkweed/entropy/shdir/run_entropy_k10_c4.sh',\n",
       " '/data/gpfs/home/tfaske/d/milkweed/entropy/shdir/run_entropy_k11_c1.sh',\n",
       " '/data/gpfs/home/tfaske/d/milkweed/entropy/shdir/run_entropy_k11_c2.sh',\n",
       " '/data/gpfs/home/tfaske/d/milkweed/entropy/shdir/run_entropy_k11_c3.sh',\n",
       " '/data/gpfs/home/tfaske/d/milkweed/entropy/shdir/run_entropy_k11_c4.sh',\n",
       " '/data/gpfs/home/tfaske/d/milkweed/entropy/shdir/run_entropy_k2_c1.sh',\n",
       " '/data/gpfs/home/tfaske/d/milkweed/entropy/shdir/run_entropy_k2_c2.sh',\n",
       " '/data/gpfs/home/tfaske/d/milkweed/entropy/shdir/run_entropy_k2_c3.sh',\n",
       " '/data/gpfs/home/tfaske/d/milkweed/entropy/shdir/run_entropy_k2_c4.sh',\n",
       " '/data/gpfs/home/tfaske/d/milkweed/entropy/shdir/run_entropy_k3_c1.sh',\n",
       " '/data/gpfs/home/tfaske/d/milkweed/entropy/shdir/run_entropy_k3_c2.sh',\n",
       " '/data/gpfs/home/tfaske/d/milkweed/entropy/shdir/run_entropy_k3_c3.sh',\n",
       " '/data/gpfs/home/tfaske/d/milkweed/entropy/shdir/run_entropy_k3_c4.sh',\n",
       " '/data/gpfs/home/tfaske/d/milkweed/entropy/shdir/run_entropy_k4_c1.sh',\n",
       " '/data/gpfs/home/tfaske/d/milkweed/entropy/shdir/run_entropy_k4_c2.sh',\n",
       " '/data/gpfs/home/tfaske/d/milkweed/entropy/shdir/run_entropy_k4_c3.sh',\n",
       " '/data/gpfs/home/tfaske/d/milkweed/entropy/shdir/run_entropy_k4_c4.sh',\n",
       " '/data/gpfs/home/tfaske/d/milkweed/entropy/shdir/run_entropy_k5_c1.sh',\n",
       " '/data/gpfs/home/tfaske/d/milkweed/entropy/shdir/run_entropy_k5_c2.sh',\n",
       " '/data/gpfs/home/tfaske/d/milkweed/entropy/shdir/run_entropy_k5_c3.sh',\n",
       " '/data/gpfs/home/tfaske/d/milkweed/entropy/shdir/run_entropy_k5_c4.sh',\n",
       " '/data/gpfs/home/tfaske/d/milkweed/entropy/shdir/run_entropy_k6_c1.sh',\n",
       " '/data/gpfs/home/tfaske/d/milkweed/entropy/shdir/run_entropy_k6_c2.sh',\n",
       " '/data/gpfs/home/tfaske/d/milkweed/entropy/shdir/run_entropy_k6_c3.sh',\n",
       " '/data/gpfs/home/tfaske/d/milkweed/entropy/shdir/run_entropy_k6_c4.sh',\n",
       " '/data/gpfs/home/tfaske/d/milkweed/entropy/shdir/run_entropy_k7_c1.sh',\n",
       " '/data/gpfs/home/tfaske/d/milkweed/entropy/shdir/run_entropy_k7_c2.sh',\n",
       " '/data/gpfs/home/tfaske/d/milkweed/entropy/shdir/run_entropy_k7_c3.sh',\n",
       " '/data/gpfs/home/tfaske/d/milkweed/entropy/shdir/run_entropy_k7_c4.sh',\n",
       " '/data/gpfs/home/tfaske/d/milkweed/entropy/shdir/run_entropy_k8_c1.sh',\n",
       " '/data/gpfs/home/tfaske/d/milkweed/entropy/shdir/run_entropy_k8_c2.sh',\n",
       " '/data/gpfs/home/tfaske/d/milkweed/entropy/shdir/run_entropy_k8_c3.sh',\n",
       " '/data/gpfs/home/tfaske/d/milkweed/entropy/shdir/run_entropy_k8_c4.sh',\n",
       " '/data/gpfs/home/tfaske/d/milkweed/entropy/shdir/run_entropy_k9_c1.sh',\n",
       " '/data/gpfs/home/tfaske/d/milkweed/entropy/shdir/run_entropy_k9_c2.sh',\n",
       " '/data/gpfs/home/tfaske/d/milkweed/entropy/shdir/run_entropy_k9_c3.sh',\n",
       " '/data/gpfs/home/tfaske/d/milkweed/entropy/shdir/run_entropy_k9_c4.sh']"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entShells = !find $ent_dir -name 'run_entropy*.sh'\n",
    "entShells = entShells.sort()\n",
    "entShells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_sbatch_entShells(entShells):\n",
    "         with open(\"shdir/sbatch_entropy.sh\", \"w\") as o:\n",
    "            o.write(\"\"\"#!/usr/bin/env bash \\n\"\"\")\n",
    "            for sh in entShells:\n",
    "                o.write(\"\"\"sbatch %s\\n\"\"\" % (sh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_sbatch_entShells(entShells)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run all entropy*sh\n",
    "    cd /data/gpfs/home/tfaske/d/milkweed/entropy/shdir\n",
    "    source activate entropy\n",
    "    bash sbatch_entropy.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use estpost to get DIC, q, and gprob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=8) # increases float print option\n",
    "pd.set_option(\"precision\", 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/gpfs/assoc/denovo/tfaske/milkweed/entropy\n"
     ]
    }
   ],
   "source": [
    "cd $ent_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./entropy_k10_c1.hdf5',\n",
       " './entropy_k10_c2.hdf5',\n",
       " './entropy_k10_c3.hdf5',\n",
       " './entropy_k10_c4.hdf5',\n",
       " './entropy_k11_c1.hdf5',\n",
       " './entropy_k11_c2.hdf5',\n",
       " './entropy_k11_c3.hdf5',\n",
       " './entropy_k11_c4.hdf5',\n",
       " './entropy_k2_c1.hdf5',\n",
       " './entropy_k2_c2.hdf5',\n",
       " './entropy_k2_c3.hdf5',\n",
       " './entropy_k2_c4.hdf5',\n",
       " './entropy_k3_c1.hdf5',\n",
       " './entropy_k3_c2.hdf5',\n",
       " './entropy_k3_c3.hdf5',\n",
       " './entropy_k3_c4.hdf5',\n",
       " './entropy_k4_c1.hdf5',\n",
       " './entropy_k4_c2.hdf5',\n",
       " './entropy_k4_c3.hdf5',\n",
       " './entropy_k4_c4.hdf5',\n",
       " './entropy_k5_c1.hdf5',\n",
       " './entropy_k5_c2.hdf5',\n",
       " './entropy_k5_c3.hdf5',\n",
       " './entropy_k5_c4.hdf5',\n",
       " './entropy_k6_c1.hdf5',\n",
       " './entropy_k6_c2.hdf5',\n",
       " './entropy_k6_c3.hdf5',\n",
       " './entropy_k6_c4.hdf5',\n",
       " './entropy_k7_c1.hdf5',\n",
       " './entropy_k7_c2.hdf5',\n",
       " './entropy_k7_c3.hdf5',\n",
       " './entropy_k7_c4.hdf5',\n",
       " './entropy_k8_c1.hdf5',\n",
       " './entropy_k8_c2.hdf5',\n",
       " './entropy_k8_c3.hdf5',\n",
       " './entropy_k8_c4.hdf5',\n",
       " './entropy_k9_c1.hdf5',\n",
       " './entropy_k9_c2.hdf5',\n",
       " './entropy_k9_c3.hdf5',\n",
       " './entropy_k9_c4.hdf5']"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hdf5_files = !find . -name '*hdf5'\n",
    "hdf5_files = hdf5_files.sort()\n",
    "hdf5_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "estpost = '/data/gpfs/home/tfaske/g/anaconda3/envs/entropy/bin/estpost.entropy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make DIC\n",
    "for i in range(0,len(hdf5_files)):\n",
    "    f = hdf5_files[i]\n",
    "    k = f.split('_')[1] #set this \n",
    "    c = f.split('_')[2].split('.hdf5')[0]\n",
    "    #print(k,c)\n",
    "    dic = \"DIC_%s_%s.txt\" % (k,c)\n",
    "    !$estpost $f -s 3 -p deviance > $dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./DIC_k10_c4.txt',\n",
       " './DIC_k2_c4.txt',\n",
       " './DIC_k7_c2.txt',\n",
       " './DIC_k2_c1.txt',\n",
       " './DIC_k6_c1.txt',\n",
       " './DIC_k10_c3.txt',\n",
       " './DIC_k3_c2.txt',\n",
       " './DIC_k10_c1.txt',\n",
       " './DIC_k4_c4.txt',\n",
       " './DIC_k4_c2.txt',\n",
       " './DIC_k7_c1.txt',\n",
       " './DIC_k7_c4.txt',\n",
       " './DIC_k5_c2.txt',\n",
       " './DIC_k6_c2.txt',\n",
       " './DIC_k4_c3.txt',\n",
       " './DIC_k7_c3.txt',\n",
       " './DIC_k3_c1.txt',\n",
       " './DIC_k2_c2.txt',\n",
       " './DIC_k11_c2.txt',\n",
       " './DIC_k5_c4.txt',\n",
       " './DIC_k8_c4.txt',\n",
       " './DIC_k6_c3.txt',\n",
       " './DIC_k8_c3.txt',\n",
       " './DIC_k8_c1.txt',\n",
       " './DIC_k4_c1.txt',\n",
       " './DIC_k2_c3.txt',\n",
       " './DIC_k8_c2.txt',\n",
       " './DIC_k11_c4.txt',\n",
       " './DIC_k10_c2.txt',\n",
       " './DIC_k9_c3.txt',\n",
       " './DIC_k9_c2.txt',\n",
       " './DIC_k11_c3.txt',\n",
       " './DIC_k11_c1.txt',\n",
       " './DIC_k6_c4.txt',\n",
       " './DIC_k3_c4.txt',\n",
       " './DIC_k9_c1.txt',\n",
       " './DIC_k5_c1.txt',\n",
       " './DIC_k3_c3.txt',\n",
       " './DIC_k5_c3.txt',\n",
       " './DIC_k9_c4.txt']"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic_files = !find . -name 'DIC*'\n",
    "dic_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file = ./entropy_k10_c4.hdf5\n",
      "parameter dimensions for deviance: samples = 5000, chains = 1\n",
      "Model deviance: 3618225.18\n",
      "Effective number of parameters: 22825096.47\n",
      "Model DIC: 26443321.66\n",
      "\n",
      "\n",
      "file = ./entropy_k2_c4.hdf5\n",
      "parameter dimensions for deviance: samples = 5000, chains = 1\n",
      "Model deviance: 4528543.68\n",
      "Effective number of parameters: 21865490.07\n",
      "Model DIC: 26394033.75\n",
      "\n",
      "\n",
      "file = ./entropy_k7_c2.hdf5\n",
      "parameter dimensions for deviance: samples = 5000, chains = 1\n",
      "Model deviance: 3800249.08\n",
      "Effective number of parameters: 6284555.37\n",
      "Model DIC: 10084804.45\n",
      "\n",
      "\n",
      "file = ./entropy_k2_c1.hdf5\n",
      "parameter dimensions for deviance: samples = 5000, chains = 1\n",
      "Model deviance: 4529367.01\n",
      "Effective number of parameters: 20258547.64\n",
      "Model DIC: 24787914.65\n",
      "\n",
      "\n",
      "file = ./entropy_k6_c1.hdf5\n",
      "parameter dimensions for deviance: samples = 5000, chains = 1\n",
      "Model deviance: 3812436.01\n",
      "Effective number of parameters: 10558602.52\n",
      "Model DIC: 14371038.53\n",
      "\n",
      "\n",
      "file = ./entropy_k10_c3.hdf5\n",
      "parameter dimensions for deviance: samples = 5000, chains = 1\n",
      "Model deviance: 3616588.66\n",
      "Effective number of parameters: 5912895.94\n",
      "Model DIC: 9529484.61\n",
      "\n",
      "\n",
      "file = ./entropy_k3_c2.hdf5\n",
      "parameter dimensions for deviance: samples = 5000, chains = 1\n",
      "Model deviance: 4325410.58\n",
      "Effective number of parameters: 13676670.45\n",
      "Model DIC: 18002081.03\n",
      "\n",
      "\n",
      "file = ./entropy_k10_c1.hdf5\n",
      "parameter dimensions for deviance: samples = 5000, chains = 1\n",
      "Model deviance: 3620483.09\n",
      "Effective number of parameters: 24628147.98\n",
      "Model DIC: 28248631.06\n",
      "\n",
      "\n",
      "file = ./entropy_k4_c4.hdf5\n",
      "parameter dimensions for deviance: samples = 5000, chains = 1\n",
      "Model deviance: 4054649.45\n",
      "Effective number of parameters: 12579169.59\n",
      "Model DIC: 16633819.04\n",
      "\n",
      "\n",
      "file = ./entropy_k4_c2.hdf5\n",
      "parameter dimensions for deviance: samples = 5000, chains = 1\n",
      "Model deviance: 4046367.87\n",
      "Effective number of parameters: 5724942.83\n",
      "Model DIC: 9771310.70\n",
      "\n",
      "\n",
      "file = ./entropy_k7_c1.hdf5\n",
      "parameter dimensions for deviance: samples = 5000, chains = 1\n",
      "Model deviance: 3801277.57\n",
      "Effective number of parameters: 6353452.77\n",
      "Model DIC: 10154730.34\n",
      "\n",
      "\n",
      "file = ./entropy_k7_c4.hdf5\n",
      "parameter dimensions for deviance: samples = 5000, chains = 1\n",
      "Model deviance: 3800138.39\n",
      "Effective number of parameters: 6604022.85\n",
      "Model DIC: 10404161.24\n",
      "\n",
      "\n",
      "file = ./entropy_k5_c2.hdf5\n",
      "parameter dimensions for deviance: samples = 5000, chains = 1\n",
      "Model deviance: 3907209.41\n",
      "Effective number of parameters: 22056918.26\n",
      "Model DIC: 25964127.67\n",
      "\n",
      "\n",
      "file = ./entropy_k6_c2.hdf5\n",
      "parameter dimensions for deviance: samples = 5000, chains = 1\n",
      "Model deviance: 3810322.04\n",
      "Effective number of parameters: 17595699.89\n",
      "Model DIC: 21406021.93\n",
      "\n",
      "\n",
      "file = ./entropy_k4_c3.hdf5\n",
      "parameter dimensions for deviance: samples = 5000, chains = 1\n",
      "Model deviance: 4055114.98\n",
      "Effective number of parameters: 8608356.75\n",
      "Model DIC: 12663471.73\n",
      "\n",
      "\n",
      "file = ./entropy_k7_c3.hdf5\n",
      "parameter dimensions for deviance: samples = 5000, chains = 1\n",
      "Model deviance: 3800994.05\n",
      "Effective number of parameters: 7774899.74\n",
      "Model DIC: 11575893.79\n",
      "\n",
      "\n",
      "file = ./entropy_k3_c1.hdf5\n",
      "parameter dimensions for deviance: samples = 5000, chains = 1\n",
      "Model deviance: 4327288.20\n",
      "Effective number of parameters: 10037715.80\n",
      "Model DIC: 14365004.00\n",
      "\n",
      "\n",
      "file = ./entropy_k2_c2.hdf5\n",
      "parameter dimensions for deviance: samples = 5000, chains = 1\n",
      "Model deviance: 4529339.35\n",
      "Effective number of parameters: 17313356.54\n",
      "Model DIC: 21842695.89\n",
      "\n",
      "\n",
      "file = ./entropy_k11_c2.hdf5\n",
      "parameter dimensions for deviance: samples = 5000, chains = 1\n",
      "Model deviance: 3484448.66\n",
      "Effective number of parameters: 9998492.09\n",
      "Model DIC: 13482940.75\n",
      "\n",
      "\n",
      "file = ./entropy_k5_c4.hdf5\n",
      "parameter dimensions for deviance: samples = 5000, chains = 1\n",
      "Model deviance: 3905079.21\n",
      "Effective number of parameters: 16356971.20\n",
      "Model DIC: 20262050.41\n",
      "\n",
      "\n",
      "file = ./entropy_k8_c4.hdf5\n",
      "parameter dimensions for deviance: samples = 5000, chains = 1\n",
      "Model deviance: 3723381.80\n",
      "Effective number of parameters: 5681761.40\n",
      "Model DIC: 9405143.19\n",
      "\n",
      "\n",
      "file = ./entropy_k6_c3.hdf5\n",
      "parameter dimensions for deviance: samples = 5000, chains = 1\n",
      "Model deviance: 3807569.07\n",
      "Effective number of parameters: 13210982.02\n",
      "Model DIC: 17018551.09\n",
      "\n",
      "\n",
      "file = ./entropy_k8_c3.hdf5\n",
      "parameter dimensions for deviance: samples = 5000, chains = 1\n",
      "Model deviance: 3722929.82\n",
      "Effective number of parameters: 6002133.00\n",
      "Model DIC: 9725062.82\n",
      "\n",
      "\n",
      "file = ./entropy_k8_c1.hdf5\n",
      "parameter dimensions for deviance: samples = 5000, chains = 1\n",
      "Model deviance: 3724179.32\n",
      "Effective number of parameters: 6468987.59\n",
      "Model DIC: 10193166.92\n",
      "\n",
      "\n",
      "file = ./entropy_k4_c1.hdf5\n",
      "parameter dimensions for deviance: samples = 5000, chains = 1\n",
      "Model deviance: 4054912.51\n",
      "Effective number of parameters: 10378962.21\n",
      "Model DIC: 14433874.72\n",
      "\n",
      "\n",
      "file = ./entropy_k2_c3.hdf5\n",
      "parameter dimensions for deviance: samples = 5000, chains = 1\n",
      "Model deviance: 4528352.74\n",
      "Effective number of parameters: 13826319.27\n",
      "Model DIC: 18354672.01\n",
      "\n",
      "\n",
      "file = ./entropy_k8_c2.hdf5\n",
      "parameter dimensions for deviance: samples = 5000, chains = 1\n",
      "Model deviance: 3723770.64\n",
      "Effective number of parameters: 8758363.99\n",
      "Model DIC: 12482134.64\n",
      "\n",
      "\n",
      "file = ./entropy_k11_c4.hdf5\n",
      "parameter dimensions for deviance: samples = 5000, chains = 1\n",
      "Model deviance: 3569474.30\n",
      "Effective number of parameters: 24089177.43\n",
      "Model DIC: 27658651.73\n",
      "\n",
      "\n",
      "file = ./entropy_k10_c2.hdf5\n",
      "parameter dimensions for deviance: samples = 5000, chains = 1\n",
      "Model deviance: 3616010.74\n",
      "Effective number of parameters: 10566547.58\n",
      "Model DIC: 14182558.32\n",
      "\n",
      "\n",
      "file = ./entropy_k9_c3.hdf5\n",
      "parameter dimensions for deviance: samples = 5000, chains = 1\n",
      "Model deviance: 3656773.08\n",
      "Effective number of parameters: 5939767.87\n",
      "Model DIC: 9596540.95\n",
      "\n",
      "\n",
      "file = ./entropy_k9_c2.hdf5\n",
      "parameter dimensions for deviance: samples = 5000, chains = 1\n",
      "Model deviance: 3652756.29\n",
      "Effective number of parameters: 5921549.67\n",
      "Model DIC: 9574305.96\n",
      "\n",
      "\n",
      "file = ./entropy_k11_c3.hdf5\n",
      "parameter dimensions for deviance: samples = 5000, chains = 1\n",
      "Model deviance: 3481068.81\n",
      "Effective number of parameters: 11181244.41\n",
      "Model DIC: 14662313.22\n",
      "\n",
      "\n",
      "file = ./entropy_k11_c1.hdf5\n",
      "parameter dimensions for deviance: samples = 5000, chains = 1\n",
      "Model deviance: 3489566.84\n",
      "Effective number of parameters: 47442754.42\n",
      "Model DIC: 50932321.25\n",
      "\n",
      "\n",
      "file = ./entropy_k6_c4.hdf5\n",
      "parameter dimensions for deviance: samples = 5000, chains = 1\n",
      "Model deviance: 3809562.98\n",
      "Effective number of parameters: 12412318.23\n",
      "Model DIC: 16221881.21\n",
      "\n",
      "\n",
      "file = ./entropy_k3_c4.hdf5\n",
      "parameter dimensions for deviance: samples = 5000, chains = 1\n",
      "Model deviance: 4325981.34\n",
      "Effective number of parameters: 9983623.41\n",
      "Model DIC: 14309604.75\n",
      "\n",
      "\n",
      "file = ./entropy_k9_c1.hdf5\n",
      "parameter dimensions for deviance: samples = 5000, chains = 1\n",
      "Model deviance: 3655454.62\n",
      "Effective number of parameters: 4945874.41\n",
      "Model DIC: 8601329.03\n",
      "\n",
      "\n",
      "file = ./entropy_k5_c1.hdf5\n",
      "parameter dimensions for deviance: samples = 5000, chains = 1\n",
      "Model deviance: 3905110.00\n",
      "Effective number of parameters: 93628546.34\n",
      "Model DIC: 97533656.34\n",
      "\n",
      "\n",
      "file = ./entropy_k3_c3.hdf5\n",
      "parameter dimensions for deviance: samples = 5000, chains = 1\n",
      "Model deviance: 4326935.65\n",
      "Effective number of parameters: 11181279.34\n",
      "Model DIC: 15508214.99\n",
      "\n",
      "\n",
      "file = ./entropy_k5_c3.hdf5\n",
      "parameter dimensions for deviance: samples = 5000, chains = 1\n",
      "Model deviance: 3903206.48\n",
      "Effective number of parameters: 21041957.05\n",
      "Model DIC: 24945163.52\n",
      "\n",
      "\n",
      "file = ./entropy_k9_c4.hdf5\n",
      "parameter dimensions for deviance: samples = 5000, chains = 1\n",
      "Model deviance: 3655293.56\n",
      "Effective number of parameters: 6779900.70\n",
      "Model DIC: 10435194.26\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for d in dic_files:\n",
    "    !cat $d\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k</th>\n",
       "      <th>DIC</th>\n",
       "      <th>chain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>26443321.66</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>26394033.75</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>10084804.45</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>24787914.65</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>14371038.53</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    k          DIC chain\n",
       "0  10  26443321.66     4\n",
       "1   2  26394033.75     4\n",
       "2   7  10084804.45     2\n",
       "3   2  24787914.65     1\n",
       "4   6  14371038.53     1"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic_list = []\n",
    "for d in dic_files:\n",
    "    k = d.split('_k')[1].split('_')[0] #set this \n",
    "    c = d.split('_c')[1].split('.txt')[0]\n",
    "    #print(k,c)\n",
    "    \n",
    "    dic = !grep 'DIC' $d\n",
    "    dic = float(re.search('(\\d+.\\d+)',str(dic)).group(0))\n",
    "    #print(dic)\n",
    "    \n",
    "    dic_list.append([k,dic,c])\n",
    "dic_df = pd.DataFrame(dic_list,columns=['k','DIC','chain'])\n",
    "dic_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_df.to_csv('dic_list.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_sum = dic_df.groupby('k').describe().DIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.0</td>\n",
       "      <td>9.55184255e+06</td>\n",
       "      <td>7.49730784e+05</td>\n",
       "      <td>8601329.03</td>\n",
       "      <td>9331061.7275</td>\n",
       "      <td>9585423.455</td>\n",
       "      <td>9.80620428e+06</td>\n",
       "      <td>10435194.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.04513769e+07</td>\n",
       "      <td>1.39197540e+06</td>\n",
       "      <td>9405143.19</td>\n",
       "      <td>9645082.9125</td>\n",
       "      <td>9959114.870</td>\n",
       "      <td>1.07654088e+07</td>\n",
       "      <td>12482134.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.05548975e+07</td>\n",
       "      <td>6.94328471e+05</td>\n",
       "      <td>10084804.45</td>\n",
       "      <td>10137248.8675</td>\n",
       "      <td>10279445.790</td>\n",
       "      <td>1.06970944e+07</td>\n",
       "      <td>11575893.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.33756190e+07</td>\n",
       "      <td>2.90022785e+06</td>\n",
       "      <td>9771310.70</td>\n",
       "      <td>11940431.4725</td>\n",
       "      <td>13548673.225</td>\n",
       "      <td>1.49838608e+07</td>\n",
       "      <td>16633819.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.55462262e+07</td>\n",
       "      <td>1.72792615e+06</td>\n",
       "      <td>14309604.75</td>\n",
       "      <td>14351154.1875</td>\n",
       "      <td>14936609.495</td>\n",
       "      <td>1.61316815e+07</td>\n",
       "      <td>18002081.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.72543732e+07</td>\n",
       "      <td>2.98169179e+06</td>\n",
       "      <td>14371038.53</td>\n",
       "      <td>15759170.5400</td>\n",
       "      <td>16620216.150</td>\n",
       "      <td>1.81154188e+07</td>\n",
       "      <td>21406021.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.96009989e+07</td>\n",
       "      <td>9.17231016e+06</td>\n",
       "      <td>9529484.61</td>\n",
       "      <td>13019289.8925</td>\n",
       "      <td>20312939.990</td>\n",
       "      <td>2.68946490e+07</td>\n",
       "      <td>28248631.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2.28448291e+07</td>\n",
       "      <td>3.53733500e+06</td>\n",
       "      <td>18354672.01</td>\n",
       "      <td>20970689.9200</td>\n",
       "      <td>23315305.270</td>\n",
       "      <td>2.51894444e+07</td>\n",
       "      <td>26394033.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2.66840567e+07</td>\n",
       "      <td>1.73946347e+07</td>\n",
       "      <td>13482940.75</td>\n",
       "      <td>14367470.1025</td>\n",
       "      <td>21160482.475</td>\n",
       "      <td>3.34770691e+07</td>\n",
       "      <td>50932321.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.21762495e+07</td>\n",
       "      <td>3.69883668e+07</td>\n",
       "      <td>20262050.41</td>\n",
       "      <td>23774385.2425</td>\n",
       "      <td>25454645.595</td>\n",
       "      <td>4.38565098e+07</td>\n",
       "      <td>97533656.34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    count            mean             std          min            25%  \\\n",
       "k                                                                       \n",
       "9     4.0  9.55184255e+06  7.49730784e+05   8601329.03   9331061.7275   \n",
       "8     4.0  1.04513769e+07  1.39197540e+06   9405143.19   9645082.9125   \n",
       "7     4.0  1.05548975e+07  6.94328471e+05  10084804.45  10137248.8675   \n",
       "4     4.0  1.33756190e+07  2.90022785e+06   9771310.70  11940431.4725   \n",
       "3     4.0  1.55462262e+07  1.72792615e+06  14309604.75  14351154.1875   \n",
       "6     4.0  1.72543732e+07  2.98169179e+06  14371038.53  15759170.5400   \n",
       "10    4.0  1.96009989e+07  9.17231016e+06   9529484.61  13019289.8925   \n",
       "2     4.0  2.28448291e+07  3.53733500e+06  18354672.01  20970689.9200   \n",
       "11    4.0  2.66840567e+07  1.73946347e+07  13482940.75  14367470.1025   \n",
       "5     4.0  4.21762495e+07  3.69883668e+07  20262050.41  23774385.2425   \n",
       "\n",
       "             50%             75%          max  \n",
       "k                                              \n",
       "9    9585423.455  9.80620428e+06  10435194.26  \n",
       "8    9959114.870  1.07654088e+07  12482134.64  \n",
       "7   10279445.790  1.06970944e+07  11575893.79  \n",
       "4   13548673.225  1.49838608e+07  16633819.04  \n",
       "3   14936609.495  1.61316815e+07  18002081.03  \n",
       "6   16620216.150  1.81154188e+07  21406021.93  \n",
       "10  20312939.990  2.68946490e+07  28248631.06  \n",
       "2   23315305.270  2.51894444e+07  26394033.75  \n",
       "11  21160482.475  3.34770691e+07  50932321.25  \n",
       "5   25454645.595  4.38565098e+07  97533656.34  "
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic_sum.sort_values('mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_sum.to_csv('dic_sum.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get gprob and q for each k, and mcmc metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file = entropy_k2_c1.hdf5\n",
      "file = entropy_k2_c2.hdf5\n",
      "file = entropy_k2_c3.hdf5\n",
      "file = entropy_k2_c4.hdf5\n",
      "parameter dimensions for q: ind = 143, populations = 2, samples = 5000, chains = 4\n",
      "file = entropy_k3_c1.hdf5\n",
      "file = entropy_k3_c2.hdf5\n",
      "file = entropy_k3_c3.hdf5\n",
      "file = entropy_k3_c4.hdf5\n",
      "parameter dimensions for q: ind = 143, populations = 3, samples = 5000, chains = 4\n",
      "file = entropy_k4_c1.hdf5\n",
      "file = entropy_k4_c2.hdf5\n",
      "file = entropy_k4_c3.hdf5\n",
      "file = entropy_k4_c4.hdf5\n",
      "parameter dimensions for q: ind = 143, populations = 4, samples = 5000, chains = 4\n",
      "file = entropy_k5_c1.hdf5\n",
      "file = entropy_k5_c2.hdf5\n",
      "file = entropy_k5_c3.hdf5\n",
      "file = entropy_k5_c4.hdf5\n",
      "parameter dimensions for q: ind = 143, populations = 5, samples = 5000, chains = 4\n",
      "file = entropy_k6_c1.hdf5\n",
      "file = entropy_k6_c2.hdf5\n",
      "file = entropy_k6_c3.hdf5\n",
      "file = entropy_k6_c4.hdf5\n",
      "parameter dimensions for q: ind = 143, populations = 6, samples = 5000, chains = 4\n",
      "file = entropy_k7_c1.hdf5\n",
      "file = entropy_k7_c2.hdf5\n",
      "file = entropy_k7_c3.hdf5\n",
      "file = entropy_k7_c4.hdf5\n",
      "parameter dimensions for q: ind = 143, populations = 7, samples = 5000, chains = 4\n",
      "file = entropy_k8_c1.hdf5\n",
      "file = entropy_k8_c2.hdf5\n",
      "file = entropy_k8_c3.hdf5\n",
      "file = entropy_k8_c4.hdf5\n",
      "parameter dimensions for q: ind = 143, populations = 8, samples = 5000, chains = 4\n",
      "file = entropy_k9_c1.hdf5\n",
      "file = entropy_k9_c2.hdf5\n",
      "file = entropy_k9_c3.hdf5\n",
      "file = entropy_k9_c4.hdf5\n",
      "parameter dimensions for q: ind = 143, populations = 9, samples = 5000, chains = 4\n",
      "file = entropy_k10_c1.hdf5\n",
      "file = entropy_k10_c2.hdf5\n",
      "file = entropy_k10_c3.hdf5\n",
      "file = entropy_k10_c4.hdf5\n",
      "parameter dimensions for q: ind = 143, populations = 10, samples = 5000, chains = 4\n",
      "file = entropy_k11_c1.hdf5\n",
      "file = entropy_k11_c2.hdf5\n",
      "file = entropy_k11_c3.hdf5\n",
      "file = entropy_k11_c4.hdf5\n",
      "parameter dimensions for q: ind = 143, populations = 11, samples = 5000, chains = 4\n"
     ]
    }
   ],
   "source": [
    "# ancestry coeffecients \n",
    "!$estpost *k2*.hdf5 -p q -s 0 -o q2.txt\n",
    "\n",
    "!$estpost *k3*.hdf5 -p q -s 0 -o q3.txt\n",
    "\n",
    "!$estpost *k4*.hdf5 -p q -s 0 -o q4.txt\n",
    "\n",
    "!$estpost *k5*.hdf5 -p q -s 0 -o q5.txt\n",
    "\n",
    "!$estpost *k6*.hdf5 -p q -s 0 -o q6.txt\n",
    "\n",
    "!$estpost *k7*.hdf5 -p q -s 0 -o q7.txt\n",
    "\n",
    "!$estpost *k8*.hdf5 -p q -s 0 -o q8.txt\n",
    "\n",
    "!$estpost *k9*.hdf5 -p q -s 0 -o q9.txt\n",
    "\n",
    "!$estpost *k10*.hdf5 -p q -s 0 -o q10.txt\n",
    "\n",
    "!$estpost *k11*.hdf5 -p q -s 0 -o q11.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file = entropy_k2_c1.hdf5\n",
      "file = entropy_k2_c2.hdf5\n",
      "file = entropy_k2_c3.hdf5\n",
      "file = entropy_k2_c4.hdf5\n",
      "parameter dimensions for q: ind = 143, populations = 2, samples = 5000, chains = 4\n",
      "file = entropy_k3_c1.hdf5\n",
      "file = entropy_k3_c2.hdf5\n",
      "file = entropy_k3_c3.hdf5\n",
      "file = entropy_k3_c4.hdf5\n",
      "parameter dimensions for q: ind = 143, populations = 3, samples = 5000, chains = 4\n",
      "file = entropy_k4_c1.hdf5\n",
      "file = entropy_k4_c2.hdf5\n",
      "file = entropy_k4_c3.hdf5\n",
      "file = entropy_k4_c4.hdf5\n",
      "parameter dimensions for q: ind = 143, populations = 4, samples = 5000, chains = 4\n",
      "file = entropy_k5_c1.hdf5\n",
      "file = entropy_k5_c2.hdf5\n",
      "file = entropy_k5_c3.hdf5\n",
      "file = entropy_k5_c4.hdf5\n",
      "parameter dimensions for q: ind = 143, populations = 5, samples = 5000, chains = 4\n",
      "file = entropy_k6_c1.hdf5\n",
      "file = entropy_k6_c2.hdf5\n",
      "file = entropy_k6_c3.hdf5\n",
      "file = entropy_k6_c4.hdf5\n",
      "parameter dimensions for q: ind = 143, populations = 6, samples = 5000, chains = 4\n",
      "file = entropy_k7_c1.hdf5\n",
      "file = entropy_k7_c2.hdf5\n",
      "file = entropy_k7_c3.hdf5\n",
      "file = entropy_k7_c4.hdf5\n",
      "parameter dimensions for q: ind = 143, populations = 7, samples = 5000, chains = 4\n",
      "file = entropy_k8_c1.hdf5\n",
      "file = entropy_k8_c2.hdf5\n",
      "file = entropy_k8_c3.hdf5\n",
      "file = entropy_k8_c4.hdf5\n",
      "parameter dimensions for q: ind = 143, populations = 8, samples = 5000, chains = 4\n",
      "file = entropy_k9_c1.hdf5\n",
      "file = entropy_k9_c2.hdf5\n",
      "file = entropy_k9_c3.hdf5\n",
      "file = entropy_k9_c4.hdf5\n",
      "parameter dimensions for q: ind = 143, populations = 9, samples = 5000, chains = 4\n",
      "file = entropy_k10_c1.hdf5\n",
      "file = entropy_k10_c2.hdf5\n",
      "file = entropy_k10_c3.hdf5\n",
      "file = entropy_k10_c4.hdf5\n",
      "parameter dimensions for q: ind = 143, populations = 10, samples = 5000, chains = 4\n",
      "file = entropy_k11_c1.hdf5\n",
      "file = entropy_k11_c2.hdf5\n",
      "file = entropy_k11_c3.hdf5\n",
      "file = entropy_k11_c4.hdf5\n",
      "parameter dimensions for q: ind = 143, populations = 11, samples = 5000, chains = 4\n"
     ]
    }
   ],
   "source": [
    "#MCMC diagnostics\n",
    "!$estpost *k2*.hdf5 -p q -s 4 -o MCMC_k2.txt\n",
    "\n",
    "!$estpost *k3*.hdf5 -p q -s 4 -o MCMC_k3.txt\n",
    "\n",
    "!$estpost *k4*.hdf5 -p q -s 4 -o MCMC_k4.txt\n",
    "\n",
    "!$estpost *k5*.hdf5 -p q -s 4 -o MCMC_k5.txt\n",
    "\n",
    "!$estpost *k6*.hdf5 -p q -s 4 -o MCMC_k6.txt\n",
    "\n",
    "!$estpost *k7*.hdf5 -p q -s 4 -o MCMC_k7.txt\n",
    "\n",
    "!$estpost *k8*.hdf5 -p q -s 4 -o MCMC_k8.txt\n",
    "\n",
    "!$estpost *k9*.hdf5 -p q -s 4 -o MCMC_k9.txt\n",
    "\n",
    "!$estpost *k10*.hdf5 -p q -s 4 -o MCMC_k10.txt\n",
    "\n",
    "!$estpost *k11*.hdf5 -p q -s 4 -o MCMC_k11.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make slurm script to make gprob file\n",
    "\n",
    "    use all k and chains to make gprob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/gpfs/assoc/denovo/tfaske/milkweed/entropy\n"
     ]
    }
   ],
   "source": [
    "cd $ent_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "### select slurm options\n",
    "account = 'cpu-s5-denovo-0'\n",
    "partition = 'cpu-core-0'\n",
    "time = '1-00:00:00' #time limit 4\n",
    "cpus = 2 #to prevent hammering one node\n",
    "mem_cpu = 6000\n",
    "email = 'tfaske@nevada.unr.edu'\n",
    "\n",
    "### select k \n",
    "num_k = [2,3,4,6,7,8,9,10,11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_gprob_k_sh(account,partition,time,cpus,mem_cpu,email,estpost,num_k):\n",
    "    for k in num_k:\n",
    "        with open(\"shdir/run_gprob_k%d.sh\" % (k), \"w\") as o:\n",
    "            o.write(\"\"\"#!/usr/bin/env bash\n",
    "#SBATCH --account=%s\n",
    "#SBATCH --partition=%s\n",
    "#SBATCH --time=%s\n",
    "#SBATCH --ntasks 1\n",
    "#SBATCH --cpus-per-task %d\n",
    "#SBATCH --mem-per-cpu=%d\n",
    "#SBATCH --job-name gprob_k%d\n",
    "#SBATCH --output output_gprob_k%d.txt\n",
    "#SBATCH --mail-type=END\n",
    "#SBATCH --mail-user=%s\\n\\n\"\"\" % (account,partition,time,cpus,mem_cpu,k,k,email))\n",
    "        \n",
    "            o.write(\"%s ../*k%d*.hdf5 -p gprob -s 0 -o ../gprob%d.txt\" % (estpost,k,k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_gprob_k_sh(account,partition,time,cpus,mem_cpu,email,estpost,num_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/data/gpfs/home/tfaske/d/milkweed/entropy/shdir/run_gprob_k10.sh',\n",
       " '/data/gpfs/home/tfaske/d/milkweed/entropy/shdir/run_gprob_k11.sh',\n",
       " '/data/gpfs/home/tfaske/d/milkweed/entropy/shdir/run_gprob_k2.sh',\n",
       " '/data/gpfs/home/tfaske/d/milkweed/entropy/shdir/run_gprob_k3.sh',\n",
       " '/data/gpfs/home/tfaske/d/milkweed/entropy/shdir/run_gprob_k4.sh',\n",
       " '/data/gpfs/home/tfaske/d/milkweed/entropy/shdir/run_gprob_k5.sh',\n",
       " '/data/gpfs/home/tfaske/d/milkweed/entropy/shdir/run_gprob_k6.sh',\n",
       " '/data/gpfs/home/tfaske/d/milkweed/entropy/shdir/run_gprob_k7.sh',\n",
       " '/data/gpfs/home/tfaske/d/milkweed/entropy/shdir/run_gprob_k8.sh',\n",
       " '/data/gpfs/home/tfaske/d/milkweed/entropy/shdir/run_gprob_k9.sh']"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gprobShells = !find $ent_dir -name 'run_gprob*.sh'\n",
    "gprobShells = gprobShells.sort()\n",
    "gprobShells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_sbatch_gprobShells(gprobShells):\n",
    "    with open(\"shdir/sbatch_gprob.sh\", \"w\") as o:\n",
    "        o.write(\"\"\"#!/usr/bin/env bash \\n\"\"\")\n",
    "        for sh in gprobShells:\n",
    "            o.write(\"\"\"sbatch %s\\n\"\"\" % (sh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_sbatch_gprobShells(gprobShells)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### gprob all "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../entropy_k2_c*hdf5',\n",
       " '../entropy_k3_c*hdf5',\n",
       " '../entropy_k4_c*hdf5',\n",
       " '../entropy_k6_c*hdf5',\n",
       " '../entropy_k7_c*hdf5',\n",
       " '../entropy_k8_c*hdf5',\n",
       " '../entropy_k9_c*hdf5',\n",
       " '../entropy_k10_c*hdf5',\n",
       " '../entropy_k11_c*hdf5']"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hdf5_files = []\n",
    "for k in num_k:\n",
    "    f = '../entropy_k' + str(k) + '_c*hdf5'\n",
    "    hdf5_files.append(f)\n",
    "hdf5_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/data/gpfs/home/tfaske/g/anaconda3/envs/entropy/bin/estpost.entropy ../entropy_k2_c*hdf5 ../entropy_k3_c*hdf5 ../entropy_k4_c*hdf5 ../entropy_k6_c*hdf5 ../entropy_k7_c*hdf5 ../entropy_k8_c*hdf5 ../entropy_k9_c*hdf5 ../entropy_k10_c*hdf5 ../entropy_k11_c*hdf5 -p gprob -s 0 -o ../gprobAll.txt'"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gprob_cmd = estpost + ' ' + ' '.join(hdf5_files) + ' -p gprob -s 0 -o ../gprobAll.txt'\n",
    "gprob_cmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "### select slurm options\n",
    "account = 'cpu-s5-denovo-0'\n",
    "partition = 'cpu-core-0'\n",
    "time = '1-00:00:00' #time limit 4\n",
    "cpus = 1 #to prevent hammering one node\n",
    "mem_cpu = 100000\n",
    "email = 'tfaske@nevada.unr.edu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_gprob_all_sh(account,partition,time,cpus,mem_cpu,email,estpost,gprob_cmd):\n",
    "        with open(\"shdir/run_gprobAll.sh\", \"w\") as o:\n",
    "            o.write(\"\"\"#!/usr/bin/env bash\n",
    "#SBATCH --account=%s\n",
    "#SBATCH --partition=%s\n",
    "#SBATCH --time=%s\n",
    "#SBATCH --ntasks 1\n",
    "#SBATCH --cpus-per-task %d\n",
    "#SBATCH --mem-per-cpu=%d\n",
    "#SBATCH --job-name gprobAll\n",
    "#SBATCH --output output_gprobAll.txt\n",
    "#SBATCH --mail-type=END\n",
    "#SBATCH --mail-user=%s\n",
    "\n",
    "%s\"\"\" % (account,partition,time,cpus,mem_cpu,email,gprob_cmd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_gprob_all_sh(account,partition,time,cpus,mem_cpu,email,estpost,gprob_cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run gprob sh \n",
    "    cd /data/gpfs/home/tfaske/d/milkweed/entropy\n",
    "    source activate entropy\n",
    "    sbatch run_gprob.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gprobs\n",
    "#!$estpost *k2*.hdf5 -p gprob -s 0 -o gprob2.txt\n",
    "\n",
    "#!$estpost *k3*.hdf5 -p gprob -s 0 -o gprob3.txt\n",
    "\n",
    "#!$estpost *k4*.hdf5 -p gprob -s 0 -o gprob4.txt\n",
    "\n",
    "#!$estpost *k5*.hdf5 -p gprob -s 0 -o gprob5.txt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
